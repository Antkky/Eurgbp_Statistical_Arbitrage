{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import External Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gym & Gym_Anytrading\n",
    "import gym\n",
    "import gym.vector\n",
    "import gym_anytrading\n",
    "\n",
    "# Pytorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Data Structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# Data Science\n",
    "import statsmodels.api as sm\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numba import jit, prange\n",
    "\n",
    "# Misc\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rolling Standard Deviation\n",
    "\n",
    "For a window size of $w$ and time index $i$, the rolling standard deviation at index $i + w - 1$ is calculated as:\n",
    "\n",
    "$$\\sigma_{i+w-1} = \\sqrt{\\frac{1}{w} \\sum_{j=i}^{i+w-1} (x_j - \\bar{x})^2}$$\n",
    "\n",
    "Where:\n",
    "- $x_j$ represents the array values at time $j$\n",
    "- $\\bar{x}$ is the mean of the array values in the current window: $\\bar{x} = \\frac{1}{w} \\sum_{j=i}^{i+w-1} x_j$\n",
    "- $w$ is the window size\n",
    "\n",
    "The function calculates this standard deviation for each possible window of size $w$ in the input array, storing the result at the end position of each window in the output array.\n",
    "\n",
    "Note that the output array values at indices $0$ through $w-2$ remain unmodified by this function, as there aren't enough preceding values to form a complete window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_rolling_std(arr, output, window):\n",
    "  n = len(arr)\n",
    "  for i in range(n - window + 1):\n",
    "      output[i + window - 1] = np.std(arr[i:i + window])\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Least Squares\n",
    "The function implements the analytical solution to the least squares problem for a linear regression with two parameters:\n",
    "\n",
    "$$\\hat{\\beta} = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "Where:\n",
    "- $X$ is the design matrix of size $n \\times 2$ (first column of ones, second column of predictor values)\n",
    "- $y$ is the response vector of size $n$\n",
    "- $\\hat{\\beta}$ is the vector of estimated coefficients $[\\beta_0, \\beta_1]$\n",
    "\n",
    "For the 2×2 matrix inversion, the function calculates:\n",
    "\n",
    "$$\\text{det} = (X^T X)_{00} \\cdot (X^T X)_{11} - (X^T X)_{01} \\cdot (X^T X)_{10}$$\n",
    "\n",
    "If $|\\text{det}| < 10^{-10}$, the function returns $[\\text{NaN}, \\text{NaN}]$ as the matrix is considered non-invertible.\n",
    "\n",
    "Otherwise, the inverse of $X^T X$ is calculated as:\n",
    "\n",
    "$$(X^T X)^{-1} = \\frac{1}{\\text{det}} \\begin{bmatrix} (X^T X)_{11} & -(X^T X)_{01} \\\\ -(X^T X)_{10} & (X^T X)_{00} \\end{bmatrix}$$\n",
    "\n",
    "Finally, the function returns:\n",
    "\n",
    "$$\\hat{\\beta} = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "This implementation is optimized for a 2×2 matrix inversion within the Numba JIT environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calc_lstsq(X, y):\n",
    "  # Solve X'X b = X'y\n",
    "  XTX = X.T @ X\n",
    "  XTy = X.T @ y\n",
    "\n",
    "  # Check if XTX is invertible\n",
    "  det = XTX[0, 0] * XTX[1, 1] - XTX[0, 1] * XTX[1, 0]\n",
    "  if abs(det) < 1e-10:\n",
    "      return np.array([np.nan, np.nan])\n",
    "\n",
    "  # Inverse of 2x2 matrix\n",
    "  inv_XTX = np.empty((2, 2))\n",
    "  inv_XTX[0, 0] = XTX[1, 1] / det\n",
    "  inv_XTX[1, 1] = XTX[0, 0] / det\n",
    "  inv_XTX[0, 1] = -XTX[0, 1] / det\n",
    "  inv_XTX[1, 0] = -XTX[1, 0] / det\n",
    "\n",
    "  # Calculate beta\n",
    "  beta = inv_XTX @ XTy\n",
    "  return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rolling Cointegration\n",
    "\n",
    "For a window size of $w$ and time index $i$, the cointegration score at index $i + w - 1$ is calculated as:\n",
    "\n",
    "$$\\text{score}_{i+w-1} = -\\frac{\\sigma(\\epsilon)}{\\mu(|\\epsilon|)}$$\n",
    "\n",
    "Where:\n",
    "- $\\epsilon$ are the residuals from the linear regression: $\\epsilon = y - (β_0 + β_1 \\cdot x)$\n",
    "- $\\sigma(\\epsilon)$ is the standard deviation of the residuals\n",
    "- $\\mu(|\\epsilon|)$ is the mean of the absolute values of the residuals\n",
    "- $β_0$ and $β_1$ are regression coefficients found using least squares\n",
    "\n",
    "The regression coefficients are calculated as:\n",
    "\n",
    "$$[β_0, β_1] = \\text{argmin}_β \\sum_{j=i}^{i+w-1} (y_j - β_0 - β_1 \\cdot x_j)^2$$\n",
    "\n",
    "Where:\n",
    "- $y_j$ represents asset1 prices at time $j$\n",
    "- $x_j$ represents asset2 prices at time $j$\n",
    "- $w$ is the window size (60 by default in the code)\n",
    "\n",
    "The score is a simplified approximation of the Augmented Dickey-Fuller (ADF) test statistic, which is used to test for stationarity in the residuals as a measure of cointegration between the two asset price series.\n",
    "\n",
    "The calculation is only performed when:\n",
    "- The standard deviation of both series within the window exceeds $\\epsilon$ (1e-10)\n",
    "- The standard deviation of the residuals exceeds $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def rolling_cointegration_score(asset1, asset2, window=60, eps=1e-10):\n",
    "  n = len(asset1)\n",
    "  if n < window:\n",
    "    raise ValueError(\"Window size too large for available data\")\n",
    "\n",
    "  scores = np.full(n, np.nan)\n",
    "\n",
    "  for i in range(n - window + 1):\n",
    "    y = asset1[i:i + window]\n",
    "    x_vals = asset2[i:i + window]\n",
    "\n",
    "    # Check if there's enough variation in both series\n",
    "    y_std = np.std(y)\n",
    "    x_std = np.std(x_vals)\n",
    "\n",
    "    if y_std < eps or x_std < eps:\n",
    "      continue\n",
    "\n",
    "    # Create design matrix\n",
    "    X = np.column_stack((np.ones(window), x_vals))\n",
    "\n",
    "    # Calculate coefficients\n",
    "    beta = calc_lstsq(X, y)\n",
    "\n",
    "    # If calculation failed, skip\n",
    "    if np.isnan(beta[0]):\n",
    "      continue\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = y - (beta[0] + beta[1] * x_vals)\n",
    "\n",
    "    # Check if residuals are essentially flat\n",
    "    if np.std(residuals) < eps:\n",
    "      continue\n",
    "\n",
    "    # Simplified ADF test statistic (using residual variance)\n",
    "    # This is a proxy for the ADF test since full ADF test is complex for numba\n",
    "    adf_stat = -np.std(residuals) / np.mean(np.abs(residuals))\n",
    "    scores[i + window - 1] = adf_stat\n",
    "\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rolling Hedge Ratio\n",
    "\n",
    "For a window size of $n$ and time index $i$, the hedge ratio $\\beta_i$ is calculated as:\n",
    "\n",
    "$$\\beta_i = \\frac{\\sum_{j=i-n+1}^{i}(x_j - \\bar{x})(y_j - \\bar{y})}{\\sum_{j=i-n+1}^{i}(x_j - \\bar{x})^2}$$\n",
    "\n",
    "Where:\n",
    "- $x_j$ represents asset2 prices at time $j$\n",
    "- $y_j$ represents asset1 prices at time $j$\n",
    "- $\\bar{x}$ is the mean of asset2 prices in the current window\n",
    "- $\\bar{y}$ is the mean of asset1 prices in the current window\n",
    "- $n$ is the window size (30 by default in the code)\n",
    "\n",
    "This formula calculates the slope (beta) of the linear regression between the two asset price series within each rolling window, which represents the optimal hedge ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_rolling_hedge_ratio_numba(asset1_prices, asset2_prices, window_size=30):\n",
    "  n = len(asset1_prices)\n",
    "  hedge_ratios = np.zeros(n)\n",
    "\n",
    "  # Fill with NaN for the first window_size-1 elements\n",
    "  hedge_ratios[:window_size-1] = np.nan\n",
    "\n",
    "  for i in range(window_size-1, n):\n",
    "    # Get the window of data\n",
    "    y = asset1_prices[i-window_size+1:i+1]\n",
    "    x = asset2_prices[i-window_size+1:i+1]\n",
    "\n",
    "    # Calculate means\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    # Calculate the numerator and denominator for the hedge ratio\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for j in range(window_size):\n",
    "      x_diff = x[j] - x_mean\n",
    "      y_diff = y[j] - y_mean\n",
    "      numerator += x_diff * y_diff\n",
    "      denominator += x_diff * x_diff\n",
    "\n",
    "    # Calculate hedge ratio (beta)\n",
    "    if denominator != 0:\n",
    "      hedge_ratios[i] = numerator / denominator\n",
    "    else:\n",
    "      hedge_ratios[i] = np.nan\n",
    "\n",
    "  return hedge_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Log Returns\n",
    "\n",
    "For a price series $P = [P_0, P_1, ..., P_n]$, the logarithmic return at time $t$ is calculated as:\n",
    "\n",
    "$$r_t = \\ln(P_t) - \\ln(P_{t-1})$$\n",
    "\n",
    "Where:\n",
    "- $r_t$ represents the logarithmic return at time $t$\n",
    "- $P_t$ represents the price at time $t$\n",
    "- $P_{t-1}$ represents the price at time $t-1$\n",
    "- $\\ln()$ is the natural logarithm function\n",
    "\n",
    "This formula calculates the continuously compounded return between two consecutive price observations. Log returns have the advantage of being additive across time and approximately equal to simple returns for small price changes.\n",
    "\n",
    "In the implementation, this is achieved by applying the natural logarithm to the entire price series and then calculating the first difference of the resulting series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_returns(prices):\n",
    "  return np.log(prices).diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import & format datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eudf = pd.read_csv(\"./Data/EURUSD.csv\", index_col='Gmt time')\n",
    "gbdf = pd.read_csv(\"./Data/GBPUSD.csv\", index_col='Gmt time')\n",
    "eudf[\"Gmt time\"] = pd.to_datetime(eudf[\"Gmt time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "gbdf[\"Gmt time\"] = pd.to_datetime(gbdf[\"Gmt time\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create price columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd = pd.DataFrame(index=eudf.index)\n",
    "ptd[\"Asset1_Price\"] = eudf[\"Close\"]\n",
    "ptd[\"Asset2_Price\"] = gbdf[\"Close\"]\n",
    "\n",
    "ptd[\"Open\"] = eudf['Open'] / gbdf['Open']\n",
    "ptd[\"High\"] = eudf['High'] / gbdf['High']\n",
    "ptd[\"Low\"] = eudf['Low'] / gbdf['Low']\n",
    "ptd[\"Close\"] = eudf['Close'] / gbdf['Close']\n",
    "ptd['Ratio_Price'] = eudf['Close'] / gbdf['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate hedge ratio column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"Hedge_Ratio\"] = calculate_rolling_hedge_ratio_numba(ptd[\"Asset1_Price\"], ptd[\"Asset2_Price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate spread z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = ptd[\"Asset1_Price\"] - ptd[\"Asset2_Price\"]\n",
    "ptd[\"Spread_ZScore\"] = (spread - spread.rolling(30).mean()) / spread.rolling(30).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation & cointegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"Rolling_Correlation\"] = ptd[\"Asset1_Price\"].rolling(30).corr(ptd[\"Asset2_Price\"])\n",
    "coint_scores = rolling_cointegration_score(ptd[\"Asset1_Price\"].values, ptd[\"Asset2_Price\"].values)\n",
    "ptd[\"Rolling_Cointegration_Score\"] = coint_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"RSI1\"] = RSIIndicator(ptd[\"Asset1_Price\"], window=14).rsi()\n",
    "ptd[\"RSI2\"] = RSIIndicator(ptd[\"Asset2_Price\"], window=14).rsi()\n",
    "ptd[\"RSI3\"] = RSIIndicator(ptd[\"Ratio_Price\"], window=14).rsi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"MACD1\"] = MACD(ptd[\"Asset1_Price\"], window_slow=26, window_fast=12, window_sign=9).macd()\n",
    "ptd[\"MACD2\"] = MACD(ptd[\"Asset2_Price\"], window_slow=26, window_fast=12, window_sign=9).macd()\n",
    "ptd[\"MACD3\"] = MACD(ptd[\"Ratio_Price\"], window_slow=26, window_fast=12, window_sign=9).macd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last touches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd.dropna(inplace=True)\n",
    "ptd.to_csv(\"./data/processed/train_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data using Pandas\n",
    "```python\n",
    "eData = pd.read_csv(\"data/EURUSDp.csv\")\n",
    "...\n",
    "```\n",
    "\n",
    "### Format datetime\n",
    "```python\n",
    "eData[\"Gmt time\"] = pd.to_datetime(eData[\"Gmt time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "...\n",
    "```\n",
    "\n",
    "### Rename Columns\n",
    "```python\n",
    "eData['open'], eData['high'], eData['low'], eData['close'] = eData['Open'], eData['High'], eData['Low'], eData['Close']\n",
    "...\n",
    "```\n",
    "\n",
    "### Set Index\n",
    "```python\n",
    "eData.set_index(\"Gmt Time\", inplace=True)\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eData = pd.read_csv(\"data/EURUSDp.csv\")\n",
    "pData = pd.read_csv(\"data/GBPUSDp.csv\")\n",
    "xData = pd.read_csv(\"data/processed/EXTRAp.csv\")\n",
    "\n",
    "eData[\"Gmt time\"] = pd.to_datetime(eData[\"Gmt time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "pData[\"Gmt time\"] = pd.to_datetime(pData[\"Gmt time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "xData[\"Gmt time\"] = pd.to_datetime(xData[\"Gmt time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "eData['open'], eData['high'], eData['low'], eData['close'] = eData['Open'], eData['High'], eData['Low'], eData['Close']\n",
    "pData['open'], pData['high'], pData['low'], pData['close'] = pData['Open'], pData['High'], pData['Low'], pData['Close']\n",
    "\n",
    "eData.set_index(\"Gmt Time\", inplace=True)\n",
    "pData.set_index(\"Gmt Time\", inplace=True)\n",
    "xData.set_index(\"Gmt Time\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reward_function():\n",
    "  pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Enviroment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_feature_positioning(history):\n",
    "  return history\n",
    "\n",
    "def dynamic_feature_unrealized(history):\n",
    "  return history\n",
    "\n",
    "def dynamic_feature_realized(history):\n",
    "  return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make_function(n: int)\n",
    "takes in an ID number `n` then return an environment with the correct information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_function(n: int):\n",
    "  match n:\n",
    "    case 1:\n",
    "      return gym.make(\n",
    "        id=\"forex-v0\",\n",
    "        name=\"EUR/USD\",\n",
    "        df=eData,\n",
    "        dynamic_feature_functions = [],\n",
    "        reward_function=reward_function,\n",
    "        verbose=True\n",
    "       )\n",
    "    case 2:\n",
    "      return gym.make(\n",
    "        id=\"forex-v0\",\n",
    "        name=\"EUR/USD\",\n",
    "        df=pData,\n",
    "        dynamic_feature_functions = [],\n",
    "        reward_function=reward_function,\n",
    "        verbose=True\n",
    "       )\n",
    "    case 3:\n",
    "      return gym.make(\n",
    "        id=\"forex-v0\",\n",
    "        name=\"EXTRA\",\n",
    "        df=xData,\n",
    "        dynamic_feature_functions = [],\n",
    "        reward_function=reward_function,\n",
    "        verbose=True\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Deep Q Learning Model\n",
    "Pytorch LSTM Model for Deep Q Learning\n",
    "\n",
    "## Constructor\n",
    "```python\n",
    "LSTM_Q_Net(input_size: int, hidden_size: int, output_size: int)\n",
    "```\n",
    "### Inputs\n",
    "- `input_size`: Number of input features\n",
    "- `hidden_size`: Number of input features\n",
    "- `output_size`: Number of input features\n",
    "\n",
    "## Overview\n",
    "```python\n",
    "forward(x: torch.tensor)\n",
    "\n",
    "save(file_name: str)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mLSTM_Q_Net\u001b[39;00m(\u001b[43mnn\u001b[49m.Module):\n\u001b[32m      2\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, hidden_size, output_size):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28msuper\u001b[39m(LSTM_Q_Net, \u001b[38;5;28mself\u001b[39m).\u001b[34m__init__\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class LSTM_Q_Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(LSTM_Q_Net, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=input_size,\n",
    "      hidden_size=hidden_size,\n",
    "      num_layers=2,\n",
    "      batch_first=True,\n",
    "    )\n",
    "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    self._init_weights()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out, hidden = self.lstm(x, hidden)\n",
    "    out = self.fc(out[:, -1, :])\n",
    "    return out, hidden\n",
    "\n",
    "  def _init_weights(self):\n",
    "    for name, param in self.named_parameters():\n",
    "      if 'weight' in name:\n",
    "        if 'lstm' in name:\n",
    "          nn.init.xavier_uniform_(param)\n",
    "        else:\n",
    "          nn.init.xavier_uniform_(param)\n",
    "      elif 'bias' in name:\n",
    "        nn.init.zeros_(param)\n",
    "\n",
    "  def save(self, file_name):\n",
    "    model_folder_path = \"./models\"\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "    file_path = os.path.join(model_folder_path, file_name)\n",
    "    torch.save(self.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingAgent:\n",
    "  def __init__(self, envs, hidden_size=128, input_size=16, output_size=4, learning_rate=1e-3,\n",
    "               gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "               seq_len=32, batch_size=64, memory_size=10000):\n",
    "\n",
    "    self.envs = envs\n",
    "\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    self.model = LSTM_Q_Net(self.input_size, hidden_size, self.output_size).to(self.device)\n",
    "    self.target_model = LSTM_Q_Net(self.input_size, hidden_size, self.output_size).to(self.device)\n",
    "    self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    self.criterion = nn.MSELoss()\n",
    "    self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "    self.scaler = GradScaler(device=self.device.type)\n",
    "\n",
    "    self.gamma = gamma\n",
    "    self.epsilon = epsilon\n",
    "    self.epsilon_min = epsilon_min\n",
    "    self.epsilon_decay = epsilon_decay\n",
    "\n",
    "    self.memory = deque(maxlen=memory_size)\n",
    "    self.seq_len = seq_len\n",
    "    self.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define TBPTT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TBPTT(memory):\n",
    "  if not memory:\n",
    "    return None, None, None, None, None, None\n",
    "\n",
    "  states, actions, rewards, next_states, dones, hidden_states = zip(*memory)\n",
    "\n",
    "  device = hidden_states[0][0].device if hidden_states else torch.device(\"cpu\")\n",
    "\n",
    "  states = torch.tensor(np.array(states), dtype=torch.float32).to(device)\n",
    "  actions = torch.tensor(actions, dtype=torch.int64).to(device).unsqueeze(1)\n",
    "  rewards = torch.tensor(rewards, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "  next_states = torch.tensor(np.array(next_states), dtype=torch.float32).to(device)\n",
    "  dones = torch.tensor(dones, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "  h_states = (torch.cat([h[0] for h in hidden_states], dim=1),\n",
    "              torch.cat([h[1] for h in hidden_states], dim=1))\n",
    "\n",
    "  return states, next_states, h_states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(state):\n",
    "  if isinstance(state, np.ndarray):\n",
    "    return np.expand_dims(state, axis=0), np.expand_dims(state, axis=0), state\n",
    "  else:\n",
    "    state_array = np.array(state)\n",
    "    return np.expand_dims(state_array, axis=0), np.expand_dims(state_array, axis=0), state_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train_on_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(agent: TrainingAgent, memory):\n",
    "  if len(memory) == 0:\n",
    "    return\n",
    "\n",
    "  states, next_states, hidden_states, actions, rewards, dones = TBPTT(memory)\n",
    "\n",
    "  with torch.no_grad(), autocast(device_type=agent.device.type, dtype=torch.float16):\n",
    "    target_q_values, _ = agent.target_model(next_states, hidden_states)\n",
    "    max_next_q_values = torch.max(target_q_values, dim=1, keepdim=True)[0]\n",
    "    target_q = rewards + (1 - dones) * agent.gamma * max_next_q_values\n",
    "\n",
    "  agent.optimizer.zero_grad()\n",
    "  with autocast(device_type=agent.device.type, dtype=torch.float16):\n",
    "    current_q_values, _ = agent.model(states, hidden_states)\n",
    "    current_q_values = current_q_values.gather(1, actions)\n",
    "    loss = agent.criterion(current_q_values, target_q)\n",
    "\n",
    "  agent.scaler.scale(loss).backward()\n",
    "  agent.scaler.step(agent.optimizer)\n",
    "  agent.scaler.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(agent: TrainingAgent, render=False):\n",
    "  state = agent.envs.reset()\n",
    "  state0, state1, state2 = expand(state)\n",
    "\n",
    "  hidden_state = (torch.zeros(agent.num_layers, 1, agent.hidden_size, dtype=torch.float16).to(agent.device),\n",
    "                  torch.zeros(agent.num_layers, 1, agent.hidden_size, dtype=torch.float16).to(agent.device))\n",
    "\n",
    "  episode_reward = 0\n",
    "  episode_memory = deque(maxlen=agent.seq_len)\n",
    "  done = False\n",
    "\n",
    "  while not done:\n",
    "    if render:\n",
    "      agent.envs.render()\n",
    "\n",
    "    state_tensor = torch.tensor(state2, dtype=torch.float32).to(agent.device).unsqueeze(0)\n",
    "\n",
    "    if np.random.rand() <= agent.epsilon:\n",
    "      action = agent.envs.action_space.sample()\n",
    "    else:\n",
    "      with torch.no_grad(), autocast(device_type=agent.device.type, dtype=torch.float16):\n",
    "        q_values, hidden_state = agent.model(state_tensor, hidden_state)\n",
    "        action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "    next_state, reward, done, _ = agent.envs.step(action)\n",
    "    next_state0, next_state1, next_state2 = expand(next_state)\n",
    "    episode_reward += reward\n",
    "\n",
    "    episode_memory.append((state2, action, reward, next_state2, done, hidden_state))\n",
    "    state0, state1, state2 = next_state0, next_state1, next_state2\n",
    "\n",
    "    if len(episode_memory) >= agent.seq_len or done:\n",
    "      train_on_batch(agent, episode_memory)\n",
    "      episode_memory = deque(maxlen=agent.seq_len)\n",
    "\n",
    "  agent.epsilon = max(agent.epsilon_min, agent.epsilon * agent.epsilon_decay)\n",
    "  return episode_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent: TrainingAgent, num_episodes=1000, target_update_frequency=10, checkpoint_frequency=100, render=False, checkpoint_path=\"model_checkpoints\"):\n",
    "  total_rewards = []\n",
    "  for episode in range(1, num_episodes + 1):\n",
    "    episode_reward = run_episode(agent, render)\n",
    "    total_rewards.append(episode_reward)\n",
    "\n",
    "    if episode % target_update_frequency == 0:\n",
    "      agent.target_model.load_state_dict(agent.model.state_dict())\n",
    "\n",
    "    if episode % checkpoint_frequency == 0:\n",
    "      import os\n",
    "      os.makedirs(checkpoint_path, exist_ok=True)\n",
    "      torch.save({\n",
    "        'episode': episode,\n",
    "        'model_state_dict': agent.model.state_dict(),\n",
    "        'optimizer_state_dict': agent.optimizer.state_dict(),\n",
    "        'reward': episode_reward,\n",
    "        'epsilon': agent.epsilon\n",
    "      }, f\"{checkpoint_path}/checkpoint_{episode}.pt\")\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "      avg_reward = sum(total_rewards[-10:]) / 10\n",
    "      print(f\"Episode {episode}/{num_episodes}, Average Reward (Last 10): {avg_reward:.2f}, Epsilon: {agent.epsilon:.2f}\")\n",
    "\n",
    "  return total_rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_size = 15\n",
    "hidden_size = 50\n",
    "output_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "seq_len = 30\n",
    "batch_size = 1024\n",
    "memory_size = 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon Decay Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_episodes = 1000\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = gym.vector.AsyncVectorEnv([\n",
    "    lambda: make_function(1),\n",
    "    lambda: make_function(2),\n",
    "    lambda: make_function(3)\n",
    "])\n",
    "\n",
    "agent = TrainingAgent(\n",
    "  envs=envs,\n",
    "  hidden_size=hidden_size,\n",
    "  learning_rate=learning_rate,\n",
    "  gamma=gamma,\n",
    "  epsilon=epsilon,\n",
    "  epsilon_min=epsilon_min,\n",
    "  epsilon_decay=epsilon_decay,\n",
    "  seq_len=seq_len,\n",
    "  batch_size=batch_size,\n",
    "  memory_size=memory_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = train(agent, 100, 10, 1, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
