{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import External Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gym & Gym_Anytrading\n",
    "import gym\n",
    "import gym.vector\n",
    "from gym.envs.registration import register\n",
    "import pytz\n",
    "from datetime import datetime, timedelta\n",
    "from gym_mtsim import MtSimulator, OrderType, Timeframe, FOREX_DATA_PATH\n",
    "\n",
    "# Pytorch Modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Data Structures\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "\n",
    "# Data Science\n",
    "import statsmodels.api as sm\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.trend import MACD\n",
    "from sklearn.linear_model import HuberRegressor, LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from numba import jit, prange\n",
    "\n",
    "# Misc\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rolling Standard Deviation\n",
    "\n",
    "For a window size of $w$ and time index $i$, the rolling standard deviation at index $i + w - 1$ is calculated as:\n",
    "\n",
    "$$\\sigma_{i+w-1} = \\sqrt{\\frac{1}{w} \\sum_{j=i}^{i+w-1} (x_j - \\bar{x})^2}$$\n",
    "\n",
    "Where:\n",
    "- $x_j$ represents the array values at time $j$\n",
    "- $\\bar{x}$ is the mean of the array values in the current window: $\\bar{x} = \\frac{1}{w} \\sum_{j=i}^{i+w-1} x_j$\n",
    "- $w$ is the window size\n",
    "\n",
    "The function calculates this standard deviation for each possible window of size $w$ in the input array, storing the result at the end position of each window in the output array.\n",
    "\n",
    "Note that the output array values at indices $0$ through $w-2$ remain unmodified by this function, as there aren't enough preceding values to form a complete window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_rolling_std(arr, output, window):\n",
    "  n = len(arr)\n",
    "  for i in range(n - window + 1):\n",
    "      output[i + window - 1] = np.std(arr[i:i + window])\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Least Squares\n",
    "The function implements the analytical solution to the least squares problem for a linear regression with two parameters:\n",
    "\n",
    "$$\\hat{\\beta} = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "Where:\n",
    "- $X$ is the design matrix of size $n \\times 2$ (first column of ones, second column of predictor values)\n",
    "- $y$ is the response vector of size $n$\n",
    "- $\\hat{\\beta}$ is the vector of estimated coefficients $[\\beta_0, \\beta_1]$\n",
    "\n",
    "For the 2×2 matrix inversion, the function calculates:\n",
    "\n",
    "$$\\text{det} = (X^T X)_{00} \\cdot (X^T X)_{11} - (X^T X)_{01} \\cdot (X^T X)_{10}$$\n",
    "\n",
    "If $|\\text{det}| < 10^{-10}$, the function returns $[\\text{NaN}, \\text{NaN}]$ as the matrix is considered non-invertible.\n",
    "\n",
    "Otherwise, the inverse of $X^T X$ is calculated as:\n",
    "\n",
    "$$(X^T X)^{-1} = \\frac{1}{\\text{det}} \\begin{bmatrix} (X^T X)_{11} & -(X^T X)_{01} \\\\ -(X^T X)_{10} & (X^T X)_{00} \\end{bmatrix}$$\n",
    "\n",
    "Finally, the function returns:\n",
    "\n",
    "$$\\hat{\\beta} = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "This implementation is optimized for a 2×2 matrix inversion within the Numba JIT environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calc_lstsq(X, y):\n",
    "  # Solve X'X b = X'y\n",
    "  XTX = X.T @ X\n",
    "  XTy = X.T @ y\n",
    "\n",
    "  # Check if XTX is invertible\n",
    "  det = XTX[0, 0] * XTX[1, 1] - XTX[0, 1] * XTX[1, 0]\n",
    "  if abs(det) < 1e-10:\n",
    "      return np.array([np.nan, np.nan])\n",
    "\n",
    "  # Inverse of 2x2 matrix\n",
    "  inv_XTX = np.empty((2, 2))\n",
    "  inv_XTX[0, 0] = XTX[1, 1] / det\n",
    "  inv_XTX[1, 1] = XTX[0, 0] / det\n",
    "  inv_XTX[0, 1] = -XTX[0, 1] / det\n",
    "  inv_XTX[1, 0] = -XTX[1, 0] / det\n",
    "\n",
    "  # Calculate beta\n",
    "  beta = inv_XTX @ XTy\n",
    "  return beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rolling Cointegration\n",
    "\n",
    "For a window size of $w$ and time index $i$, the cointegration score at index $i + w - 1$ is calculated as:\n",
    "\n",
    "$$\\text{score}_{i+w-1} = -\\frac{\\sigma(\\epsilon)}{\\mu(|\\epsilon|)}$$\n",
    "\n",
    "Where:\n",
    "- $\\epsilon$ are the residuals from the linear regression: $\\epsilon = y - (β_0 + β_1 \\cdot x)$\n",
    "- $\\sigma(\\epsilon)$ is the standard deviation of the residuals\n",
    "- $\\mu(|\\epsilon|)$ is the mean of the absolute values of the residuals\n",
    "- $β_0$ and $β_1$ are regression coefficients found using least squares\n",
    "\n",
    "The regression coefficients are calculated as:\n",
    "\n",
    "$$[β_0, β_1] = \\text{argmin}_β \\sum_{j=i}^{i+w-1} (y_j - β_0 - β_1 \\cdot x_j)^2$$\n",
    "\n",
    "Where:\n",
    "- $y_j$ represents asset1 prices at time $j$\n",
    "- $x_j$ represents asset2 prices at time $j$\n",
    "- $w$ is the window size (60 by default in the code)\n",
    "\n",
    "The score is a simplified approximation of the Augmented Dickey-Fuller (ADF) test statistic, which is used to test for stationarity in the residuals as a measure of cointegration between the two asset price series.\n",
    "\n",
    "The calculation is only performed when:\n",
    "- The standard deviation of both series within the window exceeds $\\epsilon$ (1e-10)\n",
    "- The standard deviation of the residuals exceeds $\\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def rolling_cointegration_score(asset1, asset2, window=60, eps=1e-10):\n",
    "  n = len(asset1)\n",
    "  if n < window:\n",
    "    raise ValueError(\"Window size too large for available data\")\n",
    "\n",
    "  scores = np.full(n, np.nan)\n",
    "\n",
    "  for i in range(n - window + 1):\n",
    "    y = asset1[i:i + window]\n",
    "    x_vals = asset2[i:i + window]\n",
    "    y_std = np.std(y)\n",
    "    x_std = np.std(x_vals)\n",
    "\n",
    "    if y_std < eps or x_std < eps:\n",
    "      continue\n",
    "\n",
    "    X = np.column_stack((np.ones(window), x_vals))\n",
    "    beta = calc_lstsq(X, y)\n",
    "\n",
    "    if np.isnan(beta[0]):\n",
    "      continue\n",
    "\n",
    "    residuals = y - (beta[0] + beta[1] * x_vals)\n",
    "\n",
    "    if np.std(residuals) < eps:\n",
    "      continue\n",
    "\n",
    "    adf_stat = -np.std(residuals) / np.mean(np.abs(residuals))\n",
    "    scores[i + window - 1] = adf_stat\n",
    "\n",
    "  return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Rolling Hedge Ratio\n",
    "\n",
    "For a window size of $n$ and time index $i$, the hedge ratio $\\beta_i$ is calculated as:\n",
    "\n",
    "$$\\beta_i = \\frac{\\sum_{j=i-n+1}^{i}(x_j - \\bar{x})(y_j - \\bar{y})}{\\sum_{j=i-n+1}^{i}(x_j - \\bar{x})^2}$$\n",
    "\n",
    "Where:\n",
    "- $x_j$ represents asset2 prices at time $j$\n",
    "- $y_j$ represents asset1 prices at time $j$\n",
    "- $\\bar{x}$ is the mean of asset2 prices in the current window\n",
    "- $\\bar{y}$ is the mean of asset1 prices in the current window\n",
    "- $n$ is the window size (30 by default in the code)\n",
    "\n",
    "This formula calculates the slope (beta) of the linear regression between the two asset price series within each rolling window, which represents the optimal hedge ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_rolling_hedge_ratio_numba(asset1_prices, asset2_prices, window_size=30):\n",
    "  n = len(asset1_prices)\n",
    "  hedge_ratios = np.zeros(n)\n",
    "  hedge_ratios[:window_size-1] = np.nan\n",
    "\n",
    "  for i in range(window_size-1, n):\n",
    "    y = asset1_prices[i-window_size+1:i+1]\n",
    "    x = asset2_prices[i-window_size+1:i+1]\n",
    "\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for j in range(window_size):\n",
    "      x_diff = x[j] - x_mean\n",
    "      y_diff = y[j] - y_mean\n",
    "      numerator += x_diff * y_diff\n",
    "      denominator += x_diff * x_diff\n",
    "\n",
    "    if denominator != 0:\n",
    "      hedge_ratios[i] = numerator / denominator\n",
    "    else:\n",
    "      hedge_ratios[i] = np.nan\n",
    "\n",
    "  return hedge_ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Log Returns\n",
    "\n",
    "For a price series $P = [P_0, P_1, ..., P_n]$, the logarithmic return at time $t$ is calculated as:\n",
    "\n",
    "$$r_t = \\ln(P_t) - \\ln(P_{t-1})$$\n",
    "\n",
    "Where:\n",
    "- $r_t$ represents the logarithmic return at time $t$\n",
    "- $P_t$ represents the price at time $t$\n",
    "- $P_{t-1}$ represents the price at time $t-1$\n",
    "- $\\ln()$ is the natural logarithm function\n",
    "\n",
    "This formula calculates the continuously compounded return between two consecutive price observations. Log returns have the advantage of being additive across time and approximately equal to simple returns for small price changes.\n",
    "\n",
    "In the implementation, this is achieved by applying the natural logarithm to the entire price series and then calculating the first difference of the resulting series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_log_returns(prices):\n",
    "  return np.log(prices).diff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import & format datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "eudf = pd.read_csv(\"../Data/EURUSD.csv\", index_col=\"Gmt time\")\n",
    "gbdf = pd.read_csv(\"../Data/GBPUSD.csv\", index_col=\"Gmt time\")\n",
    "eudf.index = pd.to_datetime(eudf.index, format=\"%d.%m.%Y %H:%M:%S.%f\")\n",
    "gbdf.index = pd.to_datetime(gbdf.index, format=\"%d.%m.%Y %H:%M:%S.%f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2402520"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_index = eudf.index.intersection(gbdf.index)\n",
    "eudf = eudf.reindex(common_index)\n",
    "gbdf = gbdf.reindex(common_index)\n",
    "len(common_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create price columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd = pd.DataFrame(index=common_index)\n",
    "ptd.index.name = \"Gmt time\"\n",
    "ptd[\"asset1_price\"] = eudf[\"Close\"]\n",
    "ptd[\"asset2_price\"] = gbdf[\"Close\"]\n",
    "\n",
    "ptd[\"open\"] = eudf['Open'] / gbdf['Open']\n",
    "ptd[\"high\"] = eudf['High'] / gbdf['High']\n",
    "ptd[\"low\"] = eudf['Low'] / gbdf['Low']\n",
    "ptd[\"close\"] = eudf['Close'] / gbdf['Close']\n",
    "ptd['ratio_price'] = eudf['Close'] / gbdf['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate hedge ratio column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"hedge_ratio\"] = calculate_rolling_hedge_ratio_numba(np.array(ptd[\"asset1_price\"]), np.array(ptd[\"asset2_price\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate spread z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = ptd[\"asset1_price\"] - ptd[\"asset2_price\"]\n",
    "ptd[\"spread_zscore\"] = (spread - spread.rolling(30).mean()) / spread.rolling(30).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation & cointegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"rolling_correlation\"] = ptd[\"asset1_price\"].rolling(30).corr(ptd[\"asset2_price\"])\n",
    "coint_scores = rolling_cointegration_score(ptd[\"asset1_price\"].values, ptd[\"asset2_price\"].values)\n",
    "ptd[\"rolling_cointegration_score\"] = coint_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate RSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"RSI1\"] = RSIIndicator(ptd[\"asset1_price\"], window=14).rsi()\n",
    "ptd[\"RSI2\"] = RSIIndicator(ptd[\"asset2_price\"], window=14).rsi()\n",
    "ptd[\"RSI3\"] = RSIIndicator(ptd[\"ratio_price\"], window=14).rsi()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MACD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd[\"MACD1\"] = MACD(ptd[\"asset1_price\"], window_slow=26, window_fast=12, window_sign=9).macd()\n",
    "ptd[\"MACD2\"] = MACD(ptd[\"asset2_price\"], window_slow=26, window_fast=12, window_sign=9).macd()\n",
    "ptd[\"MACD3\"] = MACD(ptd[\"ratio_price\"], window_slow=26, window_fast=12, window_sign=9).macd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scale_columns = ['asset1_price', 'asset2_price', 'open', 'high', 'low', 'close',\n",
    "       'ratio_price', 'hedge_ratio', 'spread_zscore', 'rolling_correlation',\n",
    "       'rolling_cointegration_score', 'RSI1', 'RSI2', 'RSI3', 'MACD1', 'MACD2',\n",
    "       'MACD3']\n",
    "\n",
    "ptds = pd.DataFrame(index=ptd.index)\n",
    "ptds[scale_columns] = ptd[scale_columns]\n",
    "ptds = ptds.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "tds = pd.DataFrame(scaler.fit_transform(ptds), columns=scale_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last touches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptd.dropna(inplace=True)\n",
    "ptd.to_csv(\"../data/processed/EXTRA.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "eudf['open'], eudf['high'], eudf['low'], eudf['close'] = eudf['Open'], eudf['High'], eudf['Low'], eudf['Close']\n",
    "gbdf['open'], gbdf['high'], gbdf['low'], gbdf['close'] = gbdf['Open'], gbdf['High'], gbdf['Low'], gbdf['Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Enviroment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_columns = [\"open\", \"high\", \"low\", \"close\", \"asset1_price\", \"asset2_price\", \"ratio_price\", \"hedge_ratio\", \"spread_zscore\", \"rolling_correlation\", \"rolling_cointegration_score\", \"RSI1\", \"RSI2\", \"RSI3\", \"MACD1\", \"MACD2\",\"MACD3\"]\n",
    "normal_columns = [\"open\", \"high\", \"low\", \"close\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Deep Q Learning Model\n",
    "Pytorch LSTM Model for Deep Q Learning\n",
    "\n",
    "## Constructor\n",
    "```python\n",
    "LSTM_Q_Net(input_size: int, hidden_size: int, output_size: int)\n",
    "```\n",
    "### Inputs\n",
    "- `input_size`: Number of input features\n",
    "- `hidden_size`: Number of input features\n",
    "- `output_size`: Number of input features\n",
    "\n",
    "## Overview\n",
    "```python\n",
    "forward(x: torch.tensor)\n",
    "\n",
    "save(file_name: str)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Q_Net(nn.Module):\n",
    "  def __init__(self, input_size, hidden_size, output_size):\n",
    "    super(LSTM_Q_Net, self).__init__()\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(\n",
    "      input_size=input_size,\n",
    "      hidden_size=hidden_size,\n",
    "      num_layers=2,\n",
    "      batch_first=True,\n",
    "    )\n",
    "    self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "    self._init_weights()\n",
    "\n",
    "  def forward(self, x):\n",
    "    out, hidden = self.lstm(x, hidden)\n",
    "    out = self.fc(out[:, -1, :])\n",
    "    return out, hidden\n",
    "\n",
    "  def _init_weights(self):\n",
    "    for name, param in self.named_parameters():\n",
    "      if 'weight' in name:\n",
    "        if 'lstm' in name:\n",
    "          nn.init.xavier_uniform_(param)\n",
    "        else:\n",
    "          nn.init.xavier_uniform_(param)\n",
    "      elif 'bias' in name:\n",
    "        nn.init.zeros_(param)\n",
    "\n",
    "  def save(self, file_name):\n",
    "    model_folder_path = \"./models\"\n",
    "    os.makedirs(model_folder_path, exist_ok=True)\n",
    "    file_path = os.path.join(model_folder_path, file_name)\n",
    "    torch.save(self.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingAgent:\n",
    "  def __init__(self, envs, hidden_size=128, input_size=16, output_size=4, learning_rate=1e-3,\n",
    "               gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995,\n",
    "               seq_len=32, batch_size=524, memory_size=100_000):\n",
    "\n",
    "    self.envs = envs\n",
    "\n",
    "    self.input_size = input_size\n",
    "    self.output_size = output_size\n",
    "    self.hidden_size = hidden_size\n",
    "\n",
    "    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    self.model = LSTM_Q_Net(self.input_size, hidden_size, self.output_size).to(self.device)\n",
    "    self.target_model = LSTM_Q_Net(self.input_size, hidden_size, self.output_size).to(self.device)\n",
    "    self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    self.criterion = nn.MSELoss()\n",
    "    self.optimizer = optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "    self.scaler = GradScaler(device=self.device.type)\n",
    "\n",
    "    self.gamma = gamma\n",
    "    self.epsilon = epsilon\n",
    "    self.epsilon_min = epsilon_min\n",
    "    self.epsilon_decay = epsilon_decay\n",
    "\n",
    "    self.memory = deque(maxlen=memory_size)\n",
    "    self.seq_len = seq_len\n",
    "    self.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define TBPTT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TBPTT(memory):\n",
    "  if not memory:\n",
    "    return None, None, None, None, None, None\n",
    "\n",
    "  states, actions, rewards, next_states, dones, hidden_states = zip(*memory)\n",
    "\n",
    "  device = hidden_states[0][0].device if hidden_states else torch.device(\"cpu\")\n",
    "\n",
    "  states = torch.tensor(np.array(states), dtype=torch.float32).to(device)\n",
    "  actions = torch.tensor(actions, dtype=torch.int64).to(device).unsqueeze(1)\n",
    "  rewards = torch.tensor(rewards, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "  next_states = torch.tensor(np.array(next_states), dtype=torch.float32).to(device)\n",
    "  dones = torch.tensor(dones, dtype=torch.float32).to(device).unsqueeze(1)\n",
    "\n",
    "  h_states = (torch.cat([h[0] for h in hidden_states], dim=1),\n",
    "              torch.cat([h[1] for h in hidden_states], dim=1))\n",
    "\n",
    "  return states, next_states, h_states, actions, rewards, dones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(state):\n",
    "  if isinstance(state, np.ndarray):\n",
    "    return np.expand_dims(state, axis=0), np.expand_dims(state, axis=0), state\n",
    "  else:\n",
    "    state_array = np.array(state)\n",
    "    return np.expand_dims(state_array, axis=0), np.expand_dims(state_array, axis=0), state_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define train_on_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_batch(agent: TrainingAgent, memory):\n",
    "  if len(memory) == 0:\n",
    "    return\n",
    "\n",
    "  states, next_states, hidden_states, actions, rewards, dones = TBPTT(memory)\n",
    "\n",
    "  with torch.no_grad(), autocast(device_type=agent.device.type, dtype=torch.float16):\n",
    "    target_q_values, _ = agent.target_model(next_states, hidden_states)\n",
    "    max_next_q_values = torch.max(target_q_values, dim=1, keepdim=True)[0]\n",
    "    target_q = rewards + (1 - dones) * agent.gamma * max_next_q_values\n",
    "\n",
    "  agent.optimizer.zero_grad()\n",
    "  with autocast(device_type=agent.device.type, dtype=torch.float16):\n",
    "    current_q_values, _ = agent.model(states, hidden_states)\n",
    "    current_q_values = current_q_values.gather(1, actions)\n",
    "    loss = agent.criterion(current_q_values, target_q)\n",
    "\n",
    "  agent.scaler.scale(loss).backward()\n",
    "  agent.scaler.step(agent.optimizer)\n",
    "  agent.scaler.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define run_episode()\n",
    "\n",
    "**fix the fucking execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(agent: TrainingAgent, render=False):\n",
    "  state = agent.envs.reset()\n",
    "  state0, state1, state2 = expand(state)\n",
    "\n",
    "  hidden_state = torch.zeros(agent.num_layers, 1, agent.hidden_size, dtype=torch.float16, device=agent.device)\n",
    "  hidden_state = (hidden_state, hidden_state)\n",
    "\n",
    "  episode_reward = 0\n",
    "  episode_memory = deque(maxlen=agent.seq_len)\n",
    "  done = False\n",
    "\n",
    "  with tqdm(total=len(ptd)) as pbar:\n",
    "    while not done:\n",
    "      if render:\n",
    "        agent.envs.render()\n",
    "\n",
    "      state_tensor = torch.tensor(state2, dtype=torch.float16, device=agent.device).unsqueeze(0)\n",
    "\n",
    "      if np.random.rand() <= agent.epsilon:\n",
    "        action = agent.envs.action_space.sample()\n",
    "      else:\n",
    "        with torch.no_grad(), autocast(device_type=agent.device.type, dtype=torch.float16):\n",
    "          q_values, hidden_state = agent.model(state_tensor, hidden_state)\n",
    "          action = torch.argmax(q_values, dim=1).item()\n",
    "\n",
    "      next_state, reward, done, _ = agent.envs.step(action)\n",
    "      next_state0, next_state1, next_state2 = expand(next_state)\n",
    "      episode_reward += reward.item() if isinstance(reward, torch.Tensor) else reward\n",
    "\n",
    "      episode_memory.append((state2, action, reward, next_state2, done, hidden_state))\n",
    "      state0, state1, state2 = next_state0, next_state1, next_state2\n",
    "\n",
    "      if len(episode_memory) >= agent.seq_len or done:\n",
    "        train_on_batch(agent, episode_memory)\n",
    "        episode_memory = deque(maxlen=agent.seq_len)\n",
    "\n",
    "      pbar.update(1)\n",
    "\n",
    "  agent.epsilon = max(agent.epsilon_min, agent.epsilon * agent.epsilon_decay)\n",
    "  return episode_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent: TrainingAgent, num_episodes=1000, target_update_frequency=10, checkpoint_frequency=100, render=False, checkpoint_path=\"model_checkpoints\"):\n",
    "  total_rewards = []\n",
    "  for episode in range(1, num_episodes + 1):\n",
    "    episode_reward = run_episode(agent, render)\n",
    "    total_rewards.append(episode_reward)\n",
    "\n",
    "    if episode % target_update_frequency == 0:\n",
    "      agent.target_model.load_state_dict(agent.model.state_dict())\n",
    "\n",
    "    if episode % checkpoint_frequency == 0:\n",
    "      import os\n",
    "      os.makedirs(checkpoint_path, exist_ok=True)\n",
    "      torch.save({\n",
    "        'episode': episode,\n",
    "        'model_state_dict': agent.model.state_dict(),\n",
    "        'optimizer_state_dict': agent.optimizer.state_dict(),\n",
    "        'reward': episode_reward,\n",
    "        'epsilon': agent.epsilon\n",
    "      }, f\"{checkpoint_path}/checkpoint_{episode}.pt\")\n",
    "\n",
    "    if episode % 10 == 0:\n",
    "      avg_reward = sum(total_rewards[-10:]) / 10\n",
    "      print(f\"Episode {episode}/{num_episodes}, Average Reward (Last 10): {avg_reward:.2f}, Epsilon: {agent.epsilon:.2f}\")\n",
    "\n",
    "  return total_rewards\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "input_size = 15\n",
    "hidden_size = 50\n",
    "output_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "seq_len = 30\n",
    "batch_size = 1024\n",
    "memory_size = 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epsilon Decay Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "num_episodes = 1000\n",
    "gamma = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[166]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgym_mtsim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MtSimulator, OrderType, Timeframe, FOREX_DATA_PATH\n\u001b[32m      3\u001b[39m sim = MtSimulator(\n\u001b[32m      4\u001b[39m     unit=\u001b[33m'\u001b[39m\u001b[33mUSD\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     balance=\u001b[32m50000.\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     hedge=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sim.load_symbols(FOREX_DATA_PATH):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\VectorBT_Statistical_Arbitrage\\venv\\Lib\\site-packages\\gym_mtsim\\__init__.py:13\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01menvs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MtEnv\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FOREX_DATA_PATH, STOCKS_DATA_PATH, CRYPTO_DATA_PATH, MIXED_DATA_PATH\n\u001b[32m      9\u001b[39m register(\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mforex-hedge-v0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     entry_point=\u001b[33m'\u001b[39m\u001b[33mgym_mtsim.envs:MtEnv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     12\u001b[39m     kwargs={\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33moriginal_simulator\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mMtSimulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFOREX_DATA_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhedge\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtrading_symbols\u001b[39m\u001b[33m'\u001b[39m: [\u001b[33m'\u001b[39m\u001b[33mEURUSD\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mGBPCAD\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUSDJPY\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     15\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mwindow_size\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m10\u001b[39m,\n\u001b[32m     16\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msymbol_max_orders\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m,\n\u001b[32m     17\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfee\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m symbol: \u001b[32m0.03\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mJPY\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m symbol \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0003\u001b[39m\n\u001b[32m     18\u001b[39m     }\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m register(\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mforex-unhedge-v0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     23\u001b[39m     entry_point=\u001b[33m'\u001b[39m\u001b[33mgym_mtsim.envs:MtEnv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     29\u001b[39m     }\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m register(\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mstocks-hedge-v0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     34\u001b[39m     entry_point=\u001b[33m'\u001b[39m\u001b[33mgym_mtsim.envs:MtEnv\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     41\u001b[39m     }\n\u001b[32m     42\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\VectorBT_Statistical_Arbitrage\\venv\\Lib\\site-packages\\gym_mtsim\\simulator\\mt_simulator.py:42\u001b[39m, in \u001b[36mMtSimulator.__init__\u001b[39m\u001b[34m(self, unit, balance, leverage, stop_out_level, hedge, symbols_filename)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28mself\u001b[39m.current_time: datetime = \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m symbols_filename:\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mload_symbols\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbols_filename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m     43\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfile \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msymbols_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\VectorBT_Statistical_Arbitrage\\venv\\Lib\\site-packages\\gym_mtsim\\simulator\\mt_simulator.py:73\u001b[39m, in \u001b[36mMtSimulator.load_symbols\u001b[39m\u001b[34m(self, filename)\u001b[39m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[33m'\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28mself\u001b[39m.symbols_info, \u001b[38;5;28mself\u001b[39m.symbols_data = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Projects\\VectorBT_Statistical_Arbitrage\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2728\u001b[39m, in \u001b[36mnew_block\u001b[39m\u001b[34m(values, placement, ndim, refs)\u001b[39m\n\u001b[32m   2716\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_block\u001b[39m(\n\u001b[32m   2717\u001b[39m     values,\n\u001b[32m   2718\u001b[39m     placement: BlockPlacement,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2725\u001b[39m     \u001b[38;5;66;03m# - check_ndim/ensure_block_shape already checked\u001b[39;00m\n\u001b[32m   2726\u001b[39m     \u001b[38;5;66;03m# - maybe_coerce_values already called/unnecessary\u001b[39;00m\n\u001b[32m   2727\u001b[39m     klass = get_block_type(values.dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2728\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Argument 'placement' has incorrect type (expected pandas._libs.internals.BlockPlacement, got slice)"
     ]
    }
   ],
   "source": [
    "from gym_mtsim import MtSimulator, OrderType, Timeframe, FOREX_DATA_PATH\n",
    "\n",
    "print(FOREX_DATA_PATH)\n",
    "\n",
    "sim = MtSimulator(\n",
    "    unit='USD',\n",
    "    balance=50000.,\n",
    "    leverage=100.,\n",
    "    stop_out_level=1,\n",
    "    hedge=True,\n",
    ")\n",
    "\n",
    "if not sim.load_symbols(FOREX_DATA_PATH):\n",
    "    sim.download_data(\n",
    "        symbols=['EURUSD', 'GBPUSD'],\n",
    "        time_range=(\n",
    "            datetime(2015, 1, 1, tzinfo=pytz.UTC),\n",
    "            datetime(2025, 12, 31, tzinfo=pytz.UTC)\n",
    "        ),\n",
    "        timeframe=Timeframe.M1\n",
    "    )\n",
    "    sim.save_symbols(FOREX_DATA_PATH)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "agent = TrainingAgent(\n",
    "  envs=sim,\n",
    "  hidden_size=hidden_size,\n",
    "  learning_rate=learning_rate,\n",
    "  gamma=gamma,\n",
    "  epsilon=epsilon,\n",
    "  epsilon_min=epsilon_min,\n",
    "  epsilon_decay=epsilon_decay,\n",
    "  seq_len=seq_len,\n",
    "  batch_size=batch_size,\n",
    "  memory_size=memory_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rewards = train(agent, 100, 10, 1, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
